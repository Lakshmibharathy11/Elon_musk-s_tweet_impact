[2025-05-04T22:00:50.115+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-05-04T22:00:50.134+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: tesla_stock_sentiment_final_etl.load_tweet_data manual__2025-05-04T22:00:47.284764+00:00 [queued]>
[2025-05-04T22:00:50.143+0000] {taskinstance.py:2612} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: tesla_stock_sentiment_final_etl.load_tweet_data manual__2025-05-04T22:00:47.284764+00:00 [queued]>
[2025-05-04T22:00:50.145+0000] {taskinstance.py:2865} INFO - Starting attempt 1 of 1
[2025-05-04T22:00:50.161+0000] {taskinstance.py:2888} INFO - Executing <Task(_PythonDecoratedOperator): load_tweet_data> on 2025-05-04 22:00:47.284764+00:00
[2025-05-04T22:00:50.168+0000] {standard_task_runner.py:72} INFO - Started process 5002 to run task
[2025-05-04T22:00:50.172+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'tesla_stock_sentiment_final_etl', 'load_tweet_data', 'manual__2025-05-04T22:00:47.284764+00:00', '--job-id', '22', '--raw', '--subdir', 'DAGS_FOLDER/tesla_stock_etl.py', '--cfg-path', '/tmp/tmp_41p1gih']
[2025-05-04T22:00:50.175+0000] {standard_task_runner.py:105} INFO - Job 22: Subtask load_tweet_data
[2025-05-04T22:00:50.396+0000] {task_command.py:467} INFO - Running <TaskInstance: tesla_stock_sentiment_final_etl.load_tweet_data manual__2025-05-04T22:00:47.284764+00:00 [running]> on host b3f6b00d0a7d
[2025-05-04T22:00:50.469+0000] {taskinstance.py:3131} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='tesla_stock_sentiment_final_etl' AIRFLOW_CTX_TASK_ID='load_tweet_data' AIRFLOW_CTX_EXECUTION_DATE='2025-05-04T22:00:47.284764+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2025-05-04T22:00:47.284764+00:00'
[2025-05-04T22:00:50.471+0000] {taskinstance.py:731} INFO - ::endgroup::
[2025-05-04T22:00:50.952+0000] {logging_mixin.py:190} INFO - df read
[2025-05-04T22:00:51.181+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-05-04T22:00:52.030+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-05-04T22:00:52.290+0000] {logging_mixin.py:190} INFO - records going to read
[2025-05-04T22:00:52.294+0000] {logging_mixin.py:190} INFO - 0.0 2023-05-13 05:48:56 0 0
[2025-05-04T22:00:52.965+0000] {cursor.py:1156} INFO - Number of results in first chunk: 1
[2025-05-04T22:00:52.967+0000] {taskinstance.py:3310} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 266, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/tesla_stock_etl.py", line 66, in load_tweet_data
    raise e
  File "/opt/airflow/dags/tesla_stock_etl.py", line 58, in load_tweet_data
    cur.execute(sql)
  File "/home/airflow/.local/lib/python3.9/site-packages/snowflake/connector/cursor.py", line 1087, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.9/site-packages/snowflake/connector/errors.py", line 284, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/home/airflow/.local/lib/python3.9/site-packages/snowflake/connector/errors.py", line 339, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.9/site-packages/snowflake/connector/errors.py", line 215, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): 01bc21a8-0305-25cb-0008-027b000580aa: SQL compilation error: error line 2 at position 30
invalid identifier 'CREATED_AT'
[2025-05-04T22:00:52.979+0000] {taskinstance.py:1225} INFO - Marking task as FAILED. dag_id=tesla_stock_sentiment_final_etl, task_id=load_tweet_data, run_id=manual__2025-05-04T22:00:47.284764+00:00, execution_date=20250504T220047, start_date=20250504T220050, end_date=20250504T220052
[2025-05-04T22:00:52.995+0000] {taskinstance.py:340} INFO - ::group::Post task execution logs
[2025-05-04T22:00:52.996+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 22 for task load_tweet_data (000904 (42000): 01bc21a8-0305-25cb-0008-027b000580aa: SQL compilation error: error line 2 at position 30
invalid identifier 'CREATED_AT'; 5002)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/cli.py", line 115, in wrapper
    return f(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 3004, in _run_raw_task
    return _run_raw_task(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 273, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 3158, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 3182, in _execute_task
    return _execute_task(self, context, task_orig)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 733, in _execute_callable
    return ExecutionCallableRunner(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 266, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 406, in wrapper
    return func(self, *args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
  File "/opt/airflow/dags/tesla_stock_etl.py", line 66, in load_tweet_data
    raise e
  File "/opt/airflow/dags/tesla_stock_etl.py", line 58, in load_tweet_data
    cur.execute(sql)
  File "/home/airflow/.local/lib/python3.9/site-packages/snowflake/connector/cursor.py", line 1087, in execute
    Error.errorhandler_wrapper(self.connection, self, error_class, errvalue)
  File "/home/airflow/.local/lib/python3.9/site-packages/snowflake/connector/errors.py", line 284, in errorhandler_wrapper
    handed_over = Error.hand_to_other_handler(
  File "/home/airflow/.local/lib/python3.9/site-packages/snowflake/connector/errors.py", line 339, in hand_to_other_handler
    cursor.errorhandler(connection, cursor, error_class, error_value)
  File "/home/airflow/.local/lib/python3.9/site-packages/snowflake/connector/errors.py", line 215, in default_errorhandler
    raise error_class(
snowflake.connector.errors.ProgrammingError: 000904 (42000): 01bc21a8-0305-25cb-0008-027b000580aa: SQL compilation error: error line 2 at position 30
invalid identifier 'CREATED_AT'
[2025-05-04T22:00:53.048+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-05-04T22:00:53.065+0000] {taskinstance.py:3925} ERROR - Error scheduling downstream tasks. Skipping it as this is entirely optional optimisation. There might be various reasons for it, please take a look at the stack trace to figure out if the root cause can be diagnosed and fixed. See the issue https://github.com/apache/***/issues/39717 for details and an example problem. If you would like to get help in solving root cause, open discussion with all details with your managed service support or in Airflow repository.
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 3921, in schedule_downstream_tasks
    return TaskInstance._schedule_downstream_tasks(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/utils/session.py", line 94, in wrapper
    return func(*args, **kwargs)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/taskinstance.py", line 3870, in _schedule_downstream_tasks
    partial_dag = task.dag.partial_subset(
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dag.py", line 2663, in partial_subset
    dag.task_dict = {
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dag.py", line 2664, in <dictcomp>
    t.task_id: _deepcopy_task(t)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/dag.py", line 2661, in _deepcopy_task
    return copy.deepcopy(t, memo)
  File "/usr/local/lib/python3.9/copy.py", line 153, in deepcopy
    y = copier(memo)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/models/baseoperator.py", line 1388, in __deepcopy__
    setattr(result, k, copy.deepcopy(v, memo))
  File "/usr/local/lib/python3.9/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/usr/local/lib/python3.9/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/usr/local/lib/python3.9/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/usr/local/lib/python3.9/copy.py", line 210, in _deepcopy_tuple
    y = [deepcopy(a, memo) for a in x]
  File "/usr/local/lib/python3.9/copy.py", line 210, in <listcomp>
    y = [deepcopy(a, memo) for a in x]
  File "/usr/local/lib/python3.9/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/usr/local/lib/python3.9/copy.py", line 270, in _reconstruct
    state = deepcopy(state, memo)
  File "/usr/local/lib/python3.9/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/usr/local/lib/python3.9/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/usr/local/lib/python3.9/copy.py", line 172, in deepcopy
    y = _reconstruct(x, memo, *rv)
  File "/usr/local/lib/python3.9/copy.py", line 270, in _reconstruct
    state = deepcopy(state, memo)
  File "/usr/local/lib/python3.9/copy.py", line 146, in deepcopy
    y = copier(x, memo)
  File "/usr/local/lib/python3.9/copy.py", line 230, in _deepcopy_dict
    y[deepcopy(key, memo)] = deepcopy(value, memo)
  File "/usr/local/lib/python3.9/copy.py", line 161, in deepcopy
    rv = reductor(4)
TypeError: cannot pickle '_thread.lock' object
[2025-05-04T22:00:53.070+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
